\section{Introduction}

The proliferation of Large Language Models (LLMs) has catalyzed a paradigm shift in automated document analysis, enabling unprecedented capabilities in summarization, information extraction, and question answering. However, the financial domain remains a formidable frontier where general-purpose models often falter. Financial disclosures, such as annual 10-K filings, quarterly earnings reports, and investment prospectuses, are characterized by a unique and complex topology: they densely interweave narrative prose with high-dimensional structured data in the form of tables, charts, and infographics. This multimodal interdependence is not merely cosmetic but semantic; a single sentence in a Management Discussion and Analysis (MD\&A) section—for example, "Revenue growth was primarily driven by a 15\% increase in service volume"—often acts as a key that unlocks the interpretation of a specific row in a consolidated income statement multiple pages away.

Despite the success of Retrieval-Augmented Generation (RAG) in open-domain tasks, applying standard RAG pipelines to financial contexts exposes critical architectural deficiencies. Traditional systems typically process documents by either flattening tabular data into linear text sequences or treating tables and text as disparate, unconnected modalities. This "flattening" process is destructive; it obliterates the spatial and hierarchical relationships inherent in tabular structures (e.g., the hierarchy of "Current Assets" versus "Total Assets") and severs the implicit cross-referential links that bind quantitative data to qualitative explanations. Consequently, when tasked with complex reasoning—such as "Compare the year-over-year operating margin changes excluding one-time tax benefits"—standard LLMs frequently hallucinate values, misalign temporal periods, or fail to execute multi-step arithmetic correctly. Benchmarks like FinQA and FinanceBench highlight this gap, showing that while human experts maintain near-90\% accuracy, state-of-the-art models often plateau around 76\%, a discrepancy that is unacceptable in high-stakes financial decision-making.

To bridge this performance chasm, we introduce HierFinRAG, a hierarchical multimodal framework purpose-built for the rigors of financial document understanding. Our approach departs from flat retrieval paradigms by instantiating a structure-aware processing pipeline centered on two primary innovations:

\begin{enumerate}
    \item \textbf{Table-Text Graph Neural Network (TTGNN):} We propose a novel graph-based representation that captures the document's native hierarchy. Rather than treating the document as a bag of chunks, TTGNN models sections, paragraphs, tables, and individual cells as interconnected nodes in a multimodal knowledge graph. Edges in this graph represent not just semantic similarity, but also structural containment (Table $\in$ Section) and explicit cross-references ("See Note 5"). This allows the retrieval mechanism to traverse the document structure intelligently, aggregating context from related but spatially distant elements.
    
    \item \textbf{Symbolic-Neural Fusion Reasoning:} Recognizing that LLMs are powerful linguistic engines but unreliable calculators, HierFinRAG implements a hybrid reasoning module. This component dynamically routes sub-tasks: ambiguous narrative queries are handled by the neural generator, while precise numerical operations are offloaded to a deterministic symbolic engine. This fusion ensures mathematical rigor without sacrificing the model's ability to interpret nuanced financial language.
\end{enumerate}

Our contributions are threefold. First, we formalize the HierFinRAG architecture, demonstrating how graph-based modality alignment can resolve complex cross-references. Second, we provide a comprehensive evaluation on the FinQA and FinanceBench datasets, achieving a new state-of-the-art Exact Match score of 82.5\% on FinQA. Finally, we present an ablation study analyzing the efficiency-accuracy trade-offs of our hierarchical retrieval strategy, showing that it significantly reduces token consumption while improving context relevance. By synthesizing structure, semantics, and symbolic logic, HierFinRAG offers a robust foundation for the next generation of automated financial analysts.
