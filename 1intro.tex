\section{Introduction}

Large Language Models (LLMs) have transformed how we analyze documents, but they still struggle with complex financial reports. Documents like 10-K filings and earnings reports are difficult because they mix long text explanations with detailed data tables. Understanding these documents requires connecting specific numbers in a table to the text that explains them. For example, a sentence in the "Management Discussion" section might say, "Revenue grew by 15\% due to service volume," explaining a specific row in the Income Statement located several pages away.

Most current systems, known as Retrieval-Augmented Generation (RAG), fail here because they treat text and tables separately or flatten tables into plain text. This destroys the structure of the data and breaks the link between the numbers and their explanations. As a result, when asked to "Compare operating margins excluding tax benefits," standard models often make mistakes in calculation or retrieve the wrong data. Recent benchmarks like FinQA \cite{chen2021finqa} and FinanceBench \cite{islam2023financebench} show that while human experts achieve nearly 90\% accuracy, state-of-the-art models stall around 76\%.

To solve this, we introduce \textbf{HierFinRAG}, a system designed specifically for financial documents. Unlike standard approaches, HierFinRAG understands the document's structure using two key innovations:

\begin{enumerate}
    \item \textbf{Table-Text Graph Neural Network (TTGNN):} Instead of splitting the document into independent chunks, we build a graph that connects related parts. We model sections, paragraphs, tables, and cells as nodes in this graph. We create links (edges) based on the document hierarchy (e.g., a table belongs to a section) and explicit cross-references (e.g., text saying "See Table 5"). This allows our system to "read" the document like an expert, jumping from a summary to the supporting data table to verify facts.
    
    \item \textbf{Symbolic-Neural Fusion Reasoning:} LLMs are great at reading but poor at math. We use a hybrid approach: if a question asks for a summary, the LLM answers it. If the question requires calculation (e.g., "What is the percentage growth?"), our system identifies the correct numbers and sends them to a calculator engine. This ensures the math is always correct while keeping the flexible language capabilities of the LLM.
\end{enumerate}

\textbf{Our Contributions:}
\begin{itemize}
    \item We propose a \textbf{Structure-Aware} graph approach that explicitly models accounting relationships, unlike generic document graphs.
    \item We introduce a \textbf{Probabilistic Routing} mechanism that strictly separates calculation from text generation, preventing calculation errors.
    \item We achieve a new state-of-the-art accuracy of \textbf{82.5\%} on the FinQA benchmark.
    \item We provide a comprehensive evaluation showing our method uses 40\% fewer tokens than standard methods by retrieving only the relevant data.
\end{itemize}
